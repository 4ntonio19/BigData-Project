{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee81b57-e5b2-4bda-8c02-56fe7cebd45e",
   "metadata": {},
   "source": [
    "A princípio, optei por utilizar um dicionário (hash map) global pela sua simplicidade e eficiência em armazenar diferentes datasets de maneira acessível para toda a aplicação, evitando a necessidade de reprocessamento contínuo. Além disso, essa abordagem me permite facilmente implementar uma rotina ou thread paralela para monitorar a fonte de dados CSV e detectar novas inserções. Quando houver atualizações, o CSV pode ser reprocessado, e o dicionário pode ser atualizado de forma eficiente e prática, mantendo o desempenho da aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750997b8-8919-4643-aedd-244804bb7c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_DATASETS = {}\n",
    "\n",
    "def get_global_dataset(dataset_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Atualiza a variável global com um dataset tratado.\n",
    "\n",
    "    :param dataset_name: Nome do dataset (chave) para atualização.\n",
    "    :param df: DataFrame processado.\n",
    "    \"\"\"\n",
    "    global GLOBAL_DATASETS\n",
    "    return GLOBAL_DATASETS.get(dataset_name, None)\n",
    "\n",
    "\n",
    "def add_global_dataset(dataset_name: str, df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Atualiza a variável global com um dataset tratado.\n",
    "\n",
    "    :param dataset_name: Nome do dataset (chave) para atualização.\n",
    "    :param df: DataFrame processado.\n",
    "    \"\"\"\n",
    "    global GLOBAL_DATASETS\n",
    "    GLOBAL_DATASETS[dataset_name] = df\n",
    "\n",
    "if (job_postings_df := get_global_dataset(DatasetName.JOB_POSTINGS)) is None:\n",
    "    job_postings_df = process_job_postings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7f33e8-8930-40c1-8f7c-0d8cdb7e835d",
   "metadata": {},
   "source": [
    "## Previsão de Vagas de Emprego para 2025\n",
    "A função predict_job_postings_2025 é responsável por prever o número de postagens de vagas para o ano de 2025. Para isso, utiliza dados históricos de postagens de emprego, aplicando a biblioteca Prophet para modelar e prever os valores futuros. Prophet é uma ferramenta desenvolvida pelo Facebook para previsões de séries temporais, ideal para casos com sazonalidade, como o volume de postagens de empregos.\n",
    "\n",
    "## Como a função funciona:\n",
    "Filtragem por estado: Para cada estado, filtramos as postagens de emprego relacionadas ao estado específico.\n",
    "Resample para frequência diária: A partir dos dados originais, as postagens são agrupadas em uma frequência diária usando a coluna listed_time_y_m_d, que indica a data da postagem.\n",
    "Treinamento do modelo Prophet: Usamos o DataFrame diário para treinar o modelo Prophet e prever o número de vagas no futuro.\n",
    "Previsão para 2025: Após treinar o modelo, geramos um DataFrame com datas futuras e realizamos a previsão para o ano de 2025.\n",
    "Soma das previsões: A função soma o número total de vagas previstas para o ano de 2025.\n",
    "Habilidades relacionadas: Para cada estado, também extraímos uma lista de habilidades relacionadas às vagas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b34fc-99c8-4eb2-a2ae-e4fa3b567e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_job_postings_2025(predict_job_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    states = predict_job_df['state'].unique()\n",
    "    predict_job_df['ds'] = predict_job_df['listed_time_y_m_d']\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for state in states:\n",
    "        df_state: pd.DataFrame = predict_job_df[predict_job_df['state'] ==\n",
    "                                                state]\n",
    "\n",
    "        df_weekly = df_state.set_index('ds').resample('D').size().reset_index(\n",
    "            name='y')\n",
    "\n",
    "        if df_weekly.empty or df_weekly.shape[0] < 2:\n",
    "            skills_list = ', '.join(df_state['skill_abr'].dropna().unique())\n",
    "            results.append({\n",
    "                'state': state,\n",
    "                'predicted_postings': 0,\n",
    "                'skill_abr': skills_list\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        model = Prophet()\n",
    "        model.fit(df_weekly)\n",
    "\n",
    "        future = model.make_future_dataframe(periods=365, freq='D')\n",
    "\n",
    "        forecast = model.predict(future)\n",
    "\n",
    "        total_jobs_2025 = forecast[(forecast['ds'] >= '2025-01-01') & (\n",
    "            forecast['ds'] <= '2025-12-31')]['yhat_lower'].sum()\n",
    "\n",
    "        total_jobs_2025 = round(total_jobs_2025, 0)\n",
    "\n",
    "        skills_list = ', '.join(df_state['skill_abr'].dropna().unique())\n",
    "\n",
    "        results.append({\n",
    "            'state': state,\n",
    "            'predicted_postings': total_jobs_2025,\n",
    "            'skill_abr': skills_list\n",
    "        })\n",
    "\n",
    "    for state in ALL_STATES:\n",
    "        if state not in [result['state'] for result in results]:\n",
    "            results.append({\n",
    "                'state': state,\n",
    "                'predicted_postings': 0,\n",
    "                'skill_abr': ''\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
